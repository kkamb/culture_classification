{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEMPLATE FOR CLASSIFICATION PROBLEMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#the input file contains both the trained and the non-trained (to be classified) dataset\n",
    "#it must be in csv format, with headings of the columns in the first row\n",
    "#it must also be in the same directory as this ipython notebook\n",
    "#the name must be in single or double quotes, i.e. input_file = \"random_filename.csv\"]\n",
    "#furthermore, there can be entries with null values for the text column.\n",
    "input_file = \"random_filename.csv\"\n",
    "\n",
    "#the column containing the text field [ex: text_column=\"random_text_column_name\"]:\n",
    "text_column = \"random_text_column_name\"\n",
    "\n",
    "#the column containing the binary indicator of which class each row falls into [ex: binary_classifier_column = \"binary_classifier_name\"]:\n",
    "#this is empty for the rows which haven't been classified\n",
    "binary_classifier_column = \"binary_classifier_column_name\"\n",
    "\n",
    "output_file = \"predictions.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin\n",
    "import re,csv\n",
    "\n",
    "import nltk.tokenize as tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfTransformer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn import cross_validation, grid_search\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn import linear_model, decomposition\n",
    "from sklearn import metrics, cross_validation, ensemble, svm, linear_model, naive_bayes\n",
    "import nltk\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords, words\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READING IN THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(input_file, encoding='latin-1') #reads csv into dataframe\n",
    "#df = df.dropna(subset=[text_column]) #drop row if no description (NaN)\n",
    "dfs = df[text_column]\n",
    "dfs = [dfs1.encode('utf-8') for dfs1 in dfs]\n",
    "df[text_column] = dfs\n",
    "\n",
    "Xtextcol=df[text_column] #takes only the first column\n",
    "Y=df[binary_classifier_column]\n",
    "\n",
    "## get the indices of the rows that are to be used to train the model, and the rows that need to be predicted\n",
    "index_of_nulls = df[df.isnull().any(axis=1)].index.tolist()\n",
    "index_of_trained = df[~df.isnull().any(axis=1)].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "There are two inputs to the model, as described below:\n",
    "\n",
    "(1) Xtextcol => an array containing the text fields, each row a separate text entry\n",
    "\n",
    "(2) Y => a binary indicator of which class each row falls into"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEPARATING DATA INTO TESTING & TRAINING SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(447, 3)\n",
      "(447, 9685)\n"
     ]
    }
   ],
   "source": [
    "cvect = CountVectorizer(ngram_range=(1, 2), stop_words=nltk.corpus.stopwords.words('english')) #tokenizes the text\n",
    "Xvect = cvect.fit_transform(Xtextcol)\n",
    "Xvect_names = cvect.get_feature_names()\n",
    "tfidf = TfidfTransformer()\n",
    "Xtfidf = tfidf.fit_transform(Xvect) #tfidf transformation\n",
    "\n",
    "Xscore = Xtfidf[index_of_trained,:] #training and testing dataset [i.e. made up of classified rows]\n",
    "Xpred = Xtfidf[index_of_nulls,:]\n",
    "dfY = df.dropna(subset=[binary_classifier_column]) #keeping only the Ys that are classified\n",
    "\n",
    "x_train, x_test, y_train, y_test = cross_validation.train_test_split(Xscore,dfY[binary_classifier_column],test_size=0.2)\n",
    "print(np.shape(dfY))\n",
    "print(np.shape(Xscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUILDING PIPELINE, TESTING DIFFERENT MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're going to test the above algorithms (svm, ridge, SGD, perceptron, passive agrressive, random forest) to see which one yields the best predictions. \n",
      "\n",
      "\n",
      "ALGORITHM NAME: svm \n",
      "\n",
      "svm score: 0.76\n",
      "svm confusion matrix:\n",
      "[[40  3]\n",
      " [19 28]]\n",
      "svm classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.68      0.93      0.78        43\n",
      "        4.0       0.90      0.60      0.72        47\n",
      "\n",
      "avg / total       0.80      0.76      0.75        90\n",
      "\n",
      "svm Matthew's correlation coefficient: 0.55 \n",
      " \n",
      "\n",
      "ALGORITHM NAME: ridge \n",
      "\n",
      "ridge score: 0.73\n",
      "ridge confusion matrix:\n",
      "[[42  1]\n",
      " [23 24]]\n",
      "ridge classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.65      0.98      0.78        43\n",
      "        4.0       0.96      0.51      0.67        47\n",
      "\n",
      "avg / total       0.81      0.73      0.72        90\n",
      "\n",
      "ridge Matthew's correlation coefficient: 0.54 \n",
      " \n",
      "\n",
      "ALGORITHM NAME: passive_aggressive \n",
      "\n",
      "passive_aggressive score: 0.73\n",
      "passive_aggressive confusion matrix:\n",
      "[[37  6]\n",
      " [18 29]]\n",
      "passive_aggressive classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.67      0.86      0.76        43\n",
      "        4.0       0.83      0.62      0.71        47\n",
      "\n",
      "avg / total       0.75      0.73      0.73        90\n",
      "\n",
      "passive_aggressive Matthew's correlation coefficient: 0.49 \n",
      " \n",
      "\n",
      "ALGORITHM NAME: random forest \n",
      "\n",
      "random forest score: 0.76\n",
      "random forest confusion matrix:\n",
      "[[30 13]\n",
      " [ 9 38]]\n",
      "random forest classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.77      0.70      0.73        43\n",
      "        4.0       0.75      0.81      0.78        47\n",
      "\n",
      "avg / total       0.76      0.76      0.75        90\n",
      "\n",
      "random forest Matthew's correlation coefficient: 0.51 \n",
      " \n",
      "\n",
      "ALGORITHM NAME: perceptron \n",
      "\n",
      "perceptron score: 0.81\n",
      "perceptron confusion matrix:\n",
      "[[33 10]\n",
      " [ 7 40]]\n",
      "perceptron classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.82      0.77      0.80        43\n",
      "        4.0       0.80      0.85      0.82        47\n",
      "\n",
      "avg / total       0.81      0.81      0.81        90\n",
      "\n",
      "perceptron Matthew's correlation coefficient: 0.62 \n",
      " \n",
      "\n",
      "ALGORITHM NAME: SGD \n",
      "\n",
      "SGD score: 0.79\n",
      "SGD confusion matrix:\n",
      "[[34  9]\n",
      " [10 37]]\n",
      "SGD classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.77      0.79      0.78        43\n",
      "        4.0       0.80      0.79      0.80        47\n",
      "\n",
      "avg / total       0.79      0.79      0.79        90\n",
      "\n",
      "SGD Matthew's correlation coefficient: 0.58 \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ESTIMATORS = {\n",
    "    \"svm\": svm.LinearSVC(C=1.0),\n",
    "    \"ridge\": linear_model.RidgeClassifierCV(alphas=(0.1, 0.5, 1.0, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5, 10.0),normalize=True),\n",
    "    \"SGD\": linear_model.SGDClassifier(alpha=.0001,n_iter=50,penalty=\"elasticnet\"),\n",
    "    \"perceptron\": linear_model.Perceptron(n_iter=50),\n",
    "    \"passive_aggressive\": linear_model.PassiveAggressiveClassifier(n_iter=50),\n",
    "    \"random forest\": ensemble.RandomForestClassifier(),\n",
    "}\n",
    "\n",
    "y_test_predict = dict()\n",
    "y_name = dict()\n",
    "print \"We're going to test the above algorithms (svm, ridge, SGD, perceptron, passive agrressive, random forest) to see which one yields the best predictions. \\n\\n\"\n",
    "for name, estimator in ESTIMATORS.items():\n",
    "    y_name[name] = estimator\n",
    "    y_name[name].fit(x_train, y_train)\n",
    "    y_test_predict[name] = y_name[name].predict(x_test)\n",
    "    print \"ALGORITHM NAME: %s \\n\" % name\n",
    "    print \"%s score: %.2f\" % (name, (y_name[name].score(x_test, y_test)))\n",
    "    print \"%s confusion matrix:\" % name\n",
    "    print(metrics.confusion_matrix(y_test,y_test_predict[name]))\n",
    "    print \"%s classification report:\" %name\n",
    "    print(metrics.classification_report(y_test, y_test_predict[name]))\n",
    "    print \"%s Matthew's correlation coefficient: %.2f \\n \\n\" % (name, metrics.matthews_corrcoef(y_test,y_test_predict[name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHOOSING A MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the model with the best score, or whichever other metric seems best.\n",
    "\n",
    "For example, if we wanted to use the perceptron algorithm (score: .81, second best in this run), to spit out the probabilities for the untrained dataset, we could do so using the commands below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#to calculate which class they fall into:\n",
    "class_of_predicted = y_name['perceptron'].predict(Xpred)\n",
    "\n",
    "#our confidence in our class predictions:\n",
    "scores_of_predicted = y_name['perceptron'].decision_function(Xpred)\n",
    "\n",
    "#to calculate the probability [0-.5 means 1; .5 to 1 means 4]:\n",
    "d = y_name['perceptron'].decision_function(Xpred)\n",
    "probs_of_predicted = np.exp(d) / (1 + np.exp(d)) \n",
    "\n",
    "with open(output_file, 'wb') as csvfile:\n",
    "    output_text = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "    output_text.writerow(['row_index','text','predicted class','confidence in predicted class','probability'])\n",
    "    for i in range(len(probs_of_predicted)):\n",
    "        output_text.writerow([index_of_nulls[i],df.iloc[index_of_nulls[i]][text_column].strip(),class_of_predicted[i],scores_of_predicted[i],probs_of_predicted[i]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wanted to use a different model, i.e. ridge, you would replace y_name['perceptron'] with y_name['ridge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
